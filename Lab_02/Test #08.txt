HYPERPARAMETERS:
	- batch size: 1024
	- learning rate: 0.04
	- n1: 1024
	- n2: 256
	- loss: cross_entropy
	- epochs: 20

+-------+---------------------+---------------------+
|       |      TRAIN set      |       DEV set       |
+ Epoch +----------+----------+----------+----------+
|       | Avg loss | Accuracy | Avg loss | Accuracy |
+-------+----------+----------+----------+----------+
|     0 |   0.488  |  82.28 % |   0.480  |  82.76 % |
+-------+----------+----------+----------+----------+
|     1 |   0.394  |  85.82 % |   0.398  |  85.90 % |
+-------+----------+----------+----------+----------+
|     2 |   0.365  |  86.83 % |   0.374  |  87.12 % |
+-------+----------+----------+----------+----------+
|     3 |   0.328  |  88.07 % |   0.347  |  87.58 % |
+-------+----------+----------+----------+----------+
|     4 |   0.305  |  88.89 % |   0.333  |  88.10 % |
+-------+----------+----------+----------+----------+
|     5 |   0.290  |  89.57 % |   0.326  |  87.96 % |
+-------+----------+----------+----------+----------+
|     6 |   0.284  |  89.72 % |   0.330  |  87.92 % |
+-------+----------+----------+----------+----------+
|     7 |   0.267  |  90.27 % |   0.313  |  88.88 % |
+-------+----------+----------+----------+----------+
|     8 |   0.252  |  90.90 % |   0.305  |  88.50 % |
+-------+----------+----------+----------+----------+
|     9 |   0.239  |  91.35 % |   0.302  |  88.84 % |
+-------+----------+----------+----------+----------+
|    10 |   0.225  |  91.83 % |   0.298  |  89.56 % |
+-------+----------+----------+----------+----------+
|    11 |   0.234  |  91.32 % |   0.315  |  88.62 % |
+-------+----------+----------+----------+----------+
|    12 |   0.202  |  92.81 % |   0.284  |  89.70 % |
+-------+----------+----------+----------+----------+
|    13 |   0.211  |  92.20 % |   0.310  |  88.62 % |
+-------+----------+----------+----------+----------+
|    14 |   0.197  |  92.71 % |   0.301  |  89.40 % |
+-------+----------+----------+----------+----------+
|    15 |   0.181  |  93.40 % |   0.298  |  89.18 % |
+-------+----------+----------+----------+----------+
|    16 |   0.171  |  94.05 % |   0.290  |  89.54 % |
+-------+----------+----------+----------+----------+
|    17 |   0.153  |  94.74 % |   0.278  |  90.12 % |
+-------+----------+----------+----------+----------+
|    18 |   0.167  |  94.07 % |   0.292  |  89.44 % |
+-------+----------+----------+----------+----------+
|    19 |   0.153  |  94.62 % |   0.291  |  89.86 % |
+-------+----------+----------+----------+----------+

Reducing batch size greately improved learning and reduced loss.
There is now a problem of variance
